{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing necessary packages, can ask the users to restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HDODJsdzNY3t",
    "outputId": "20c23249-521b-48bb-a53f-c635f4f46cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.19.3)\n",
      "Requirement already satisfied: PyMuPDF in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.24.10)\n",
      "Requirement already satisfied: python-docx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.1.2)\n",
      "Requirement already satisfied: opencv-python in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: torch in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.2.1+cu121)\n",
      "Requirement already satisfied: torchvision==0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: pillow==8.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (8.3.1)\n",
      "Requirement already satisfied: tensorflow==2.15 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: gdown in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (5.2.0)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision==0.2.1) (1.26.4)\n",
      "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torchvision==0.2.1) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (3.3.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (72.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (1.66.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image) (3.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image) (2024.8.30)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from scikit-image) (1.7.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from PyMuPDF) (1.24.10)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: sympy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.68)\n",
      "Requirement already satisfied: beautifulsoup4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: requests[socks] in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from gdown) (4.66.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.34.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests[socks]->gdown) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests[socks]->gdown) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "# !sudo apt-get install -y libjpeg-dev zlib1g-dev # Do this, if pillow fails\n",
    "%pip install scikit-image PyMuPDF python-docx opencv-python scipy torch torchvision==0.2.1 pillow==8.3.1 tensorflow==2.15 gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stHue-JK4Et3"
   },
   "source": [
    "You will be prompted to Restart the session. Continue running the cells after restarting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elI3lOO-NZtO"
   },
   "source": [
    "# Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FNy5s-zyOOKw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-20 18:22:36.398512: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-20 18:22:36.430134: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-20 18:22:36.430177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-20 18:22:36.430910: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-20 18:22:36.436434: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-20 18:22:37.156694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Data Pre-processing\n",
    "import fitz\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "from docx import Document\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from IPython.display import clear_output as cls\n",
    "\n",
    "# Data\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow.data as tfd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zjB7D6BOO17"
   },
   "source": [
    "# Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PS6eYteOToV",
    "outputId": "9c6ee95d-fa99-4734-e3c0-7ca2bb1803c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): http://drive.google.com/uc?id=1r7TjJ9RjNZHxAzKhd4uOaRWanrQXIqw8\n",
      "From (redirected): https://drive.google.com/uc?id=1r7TjJ9RjNZHxAzKhd4uOaRWanrQXIqw8&confirm=t&uuid=6b341f81-7ceb-4c6c-81a2-4a022c6ce25b\n",
      "To: /teamspace/studios/this_studio/utils.py\n",
      "100%|██████████████████████████████████████| 17.0k/17.0k [00:00<00:00, 56.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Dataset on collab/local notebook\n",
    "\n",
    "# Virtuosa ( Dataset 1)\n",
    "!gdown 'http://drive.google.com/uc?id=10NX_UbV2HMbPEO2fvKYAIXOOOec0g38g'  # Downloading link for Ancient Text\n",
    "!gdown 'http://drive.google.com/uc?id=1YTaqNoZCYP74AuQxlyJsiQLhcoc8DNSv'  # Downloading link for Ground Truth Text\n",
    "\n",
    "# Perfecto ( Dataset 2)\n",
    "!gdown 'http://drive.google.com/uc?id=1x6FS3z4WhsHS7s38a2oSH8JnLQ_u_f21'  # Downloading link for Ancient Text\n",
    "!gdown 'http://drive.google.com/uc?id=1YqQ04ZQR4xdjKlQS9xL9zkkWYx_Ppxwa'  # Downloading link for Ground Truth Text\n",
    "\n",
    "!gdown 'http://drive.google.com/uc?id=1r7TjJ9RjNZHxAzKhd4uOaRWanrQXIqw8' # Downloading utils.py from cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t1_XnH9QOrbE",
    "outputId": "ea35c38d-2397-4c90-8d11-64e3ccb842a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset_Generation.ipynb\n",
      "'Final2_HumanAI (3).ipynb'\n",
      " Model.ipynb\n",
      "'Padilla - 1 Nobleza virtuosa_testTranscription.docx'\n",
      "'Padilla - 2 Noble perfecto_Extract.pdf'\n",
      "'Padilla - 2 Noble perfecto_Transcription.docx'\n",
      "'Padilla - Nobleza virtuosa_testExtract.pdf'\n",
      " __pycache__\n",
      " utils.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjsuG_mJOwBk"
   },
   "source": [
    "# Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3g_AanojUG3"
   },
   "source": [
    "### Converting PDF to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BiOV4cLmOxFT"
   },
   "outputs": [],
   "source": [
    "from utils import pdf_to_images\n",
    "\n",
    "pdf_path1 = \"./Padilla - Nobleza virtuosa_testExtract.pdf\"  # Path to the PDF file\n",
    "unproc_images_folder_1 = \"./preprocessing/imgsUnProcessed1\"  # Output folder to save the images\n",
    "if not os.path.exists(unproc_images_folder_1):\n",
    "    os.makedirs(unproc_images_folder_1)\n",
    "pdf_to_images(pdf_path1, unproc_images_folder_1)\n",
    "\n",
    "\n",
    "pdf_path2 = \"./Padilla - 2 Noble perfecto_Extract.pdf\"  # Path to the PDF file\n",
    "unproc_images_folder_2 = \"./preprocessing/imgsUnProcessed2\"  # Output folder to save the images\n",
    "if not os.path.exists(unproc_images_folder_2):\n",
    "    os.makedirs(unproc_images_folder_2)\n",
    "pdf_to_images(pdf_path2, unproc_images_folder_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95x4qua187Mb"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ML4SCI/DeepLearnHackathon/main/NLPRenaissanceChallenge/images/imageOriginal.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0GKH7lTjtUP"
   },
   "source": [
    "### Splitting two sided scanned images into individual pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxE9-mExPPQp",
    "outputId": "18641458-dd00-4dfc-eae8-b068957c52eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image processing complete!\n"
     ]
    }
   ],
   "source": [
    "#Segregating 2-sided pages into individual pages\n",
    "from utils import process_images\n",
    "\n",
    "unproc_images_folder_1 = \"./preprocessing/imgsUnProcessed1\"\n",
    "proc_images_folder_1 = \"./preprocessing/imgsForAllPages1\"\n",
    "if not os.path.exists(proc_images_folder_1):\n",
    "    os.makedirs(proc_images_folder_1)\n",
    "process_images(unproc_images_folder_1, proc_images_folder_1)\n",
    "\n",
    "\n",
    "unproc_images_folder_2 = \"./preprocessing/imgsUnProcessed2\"\n",
    "proc_images_folder_2 = \"./preprocessing/imgsForAllPages2\"\n",
    "if not os.path.exists(proc_images_folder_2):\n",
    "    os.makedirs(proc_images_folder_2)\n",
    "process_images(unproc_images_folder_2, proc_images_folder_2)\n",
    "\n",
    "\n",
    "print(\"Image processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DegjoeDpj6XO"
   },
   "source": [
    "# Text Detection\n",
    "### Extracting words from a scanned text page image can be achieved using any model of your choice. We are using the [CRAFT Model](https://github.com/clovaai/CRAFT-pytorch) for the same. (This will take 1-2 mins to process the entire model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WihUk3I9PO-_",
    "outputId": "f2e7c4ed-af34-40ca-f2fb-cf366221530b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth)\n",
      "elapsed time : 38.11154103279114s/imgsForAllPages1/image_9.pngg\n"
     ]
    }
   ],
   "source": [
    "#It generally takes about ~3-4 mins\n",
    "!python3 CRAFT_Model/CRAFT/BoundBoxFunc/test.py --result_folder='./preprocessing/BoundBoxApplied1/' --test_folder=\"./preprocessing/imgsForAllPages1\" --trained_model='CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth)\n",
      "elapsed time : 37.45102119445801s/imgsForAllPages2/image_9.pngg\n"
     ]
    }
   ],
   "source": [
    "#It generally takes about ~3-4 mins\n",
    "!python3 CRAFT_Model/CRAFT/BoundBoxFunc/test.py --result_folder='./preprocessing/BoundBoxApplied2/' --test_folder=\"./preprocessing/imgsForAllPages2\" --trained_model='CRAFT_Model/CRAFT/BoundBoxFunc/weights/craft_mlt_25k.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAN5mE9UlMtT"
   },
   "source": [
    "### The output of this model provides coordinates of the polygon enclosing the word. Using these coordinates one can draw a bounding box and crop word images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "IOkMKjs1QKTA"
   },
   "outputs": [],
   "source": [
    "#Sorting the BB based on the Spanish writing style\n",
    "from utils import sort_bounding_boxes\n",
    "\n",
    "bound_box_applied1 = './preprocessing/BoundBoxApplied1/'\n",
    "bound_box_sorted1 = \"./preprocessing/BoundBoxSorted1\"\n",
    "if not os.path.exists(bound_box_sorted1):\n",
    "    os.makedirs(bound_box_sorted1)\n",
    "sort_bounding_boxes(bound_box_applied1, bound_box_sorted1)\n",
    "\n",
    "bound_box_applied2 = './preprocessing/BoundBoxApplied2/'\n",
    "bound_box_sorted2 = \"./preprocessing/BoundBoxSorted2\"\n",
    "if not os.path.exists(bound_box_sorted2):\n",
    "    os.makedirs(bound_box_sorted2)\n",
    "sort_bounding_boxes(bound_box_applied2, bound_box_sorted2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lEq-eGQAnHz"
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/ML4SCI/DeepLearnHackathon/main/NLPRenaissanceChallenge/images/imageCRAFT.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55_AJ77JmRK1"
   },
   "source": [
    "### Extracting all the words from .docx file containing Transcription (True lables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ovyxoTMNQKQf"
   },
   "outputs": [],
   "source": [
    "#ground truth to text code\n",
    "from utils import save_pages_to_text\n",
    "\n",
    "docx_file1 = \"./Padilla - 1 Nobleza virtuosa_testTranscription.docx\"\n",
    "grnd_truth1 = \"./preprocessing/all_text1.txt\"     # File where the complete processed text will be saved\n",
    "save_pages_to_text(docx_file1, grnd_truth1)\n",
    "\n",
    "docx_file2 = \"./Padilla - 2 Noble perfecto_Transcription.docx\"\n",
    "grnd_truth2 = \"./preprocessing/all_text2.txt\"     # File where the complete processed text will be saved\n",
    "save_pages_to_text(docx_file2, grnd_truth2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVtXy1SrmqSF"
   },
   "source": [
    "### Since we have processed our text book into individual pages, we need to split the entire transcription based on text pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTtUbDhzQPW-",
    "outputId": "adb32158-5425-4700-bad4-fb0157567209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 files in the folder\n",
      "31 files in the folder\n",
      "Text splitting complete!\n"
     ]
    }
   ],
   "source": [
    "#splitting text files, based on the text\n",
    "from utils import process_textfiles\n",
    "\n",
    "grnd_truth1 = \"./preprocessing/all_text1.txt\"\n",
    "bound_box_sorted1 = './preprocessing/BoundBoxSorted1'\n",
    "proc_grnd_truth1 = \"./preprocessing/textSplitted1\"\n",
    "TEST_SIZE=6\n",
    "if not os.path.exists(proc_grnd_truth1):\n",
    "    os.makedirs(proc_grnd_truth1)\n",
    "process_textfiles(grnd_truth1, bound_box_sorted1, proc_grnd_truth1, TEST_SIZE)\n",
    "\n",
    "\n",
    "grnd_truth2 = \"./preprocessing/all_text2.txt\" \n",
    "bound_box_sorted2 = './preprocessing/BoundBoxSorted2'\n",
    "proc_grnd_truth2 = \"./preprocessing/textSplitted2\"\n",
    "TEST_SIZE=0\n",
    "if not os.path.exists(proc_grnd_truth2):\n",
    "    os.makedirs(proc_grnd_truth2)\n",
    "process_textfiles(grnd_truth2, bound_box_sorted2, proc_grnd_truth2, TEST_SIZE)\n",
    "print(\"Text splitting complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xz7pSRIEFoiC"
   },
   "source": [
    "### Extracts and saves bounding boxes from images using text data for filenames, skipping the last 6 images for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dqDd50FKQPUm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pages 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pages 31\n"
     ]
    }
   ],
   "source": [
    "from utils import apply_extraction_to_folder_for_train, count_files_in_folder\n",
    "\n",
    "proc_images_folder_1 = './preprocessing/imgsForAllPages1'\n",
    "bound_box_sorted1 = './preprocessing/BoundBoxSorted1'\n",
    "proc_grnd_truth1 = './preprocessing/textSplitted1'\n",
    "training_data1 = './traning_data1'\n",
    "test_size=6\n",
    "train_size = count_files_in_folder(proc_images_folder_1, ['.png', '.jpeg', '.jpg'])- test_size\n",
    "print(\"Training pages \" +  str(train_size))\n",
    "if not os.path.exists(training_data1):\n",
    "    os.makedirs(training_data1)\n",
    "apply_extraction_to_folder_for_train(proc_images_folder_1, bound_box_sorted1, proc_grnd_truth1, training_data1, train_size)\n",
    "\n",
    "\n",
    "proc_images_folder_2 = './preprocessing/imgsForAllPages2'\n",
    "bound_box_sorted2 = './preprocessing/BoundBoxSorted2'\n",
    "proc_grnd_truth2 = './preprocessing/textSplitted2'\n",
    "training_data2 = './traning_data2'\n",
    "test_size = 0\n",
    "train_size = count_files_in_folder(proc_images_folder_1, ['.png', '.jpeg', '.jpg'])- test_size\n",
    "print(\"Training pages \" +  str(train_size))\n",
    "if not os.path.exists(training_data2):\n",
    "    os.makedirs(training_data2)\n",
    "apply_extraction_to_folder_for_train(proc_images_folder_2, bound_box_sorted2, proc_grnd_truth2, training_data2, train_size) # better to send no. of pages given in transcription"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
